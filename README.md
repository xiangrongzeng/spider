# spider
爬虫应用
tools包含几个工具。
Page.py有三种方式来获取不同的网页。
其中proxy_fetch()可以自动通过调用代理来获取网页，当代理失效时能自动切换代理。test_proxy_fetch()其实是一个获取百度百科条目的爬虫
